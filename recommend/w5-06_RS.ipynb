{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**用之前准备好的数据做协同过滤，最后将所有信息串起来生成新的训练测试数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所有特征串联起来，构成RS_Train.csv\n",
    "#RS_Test.csv\n",
    "#为最后推荐系统做准备\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy.sparse as ss\n",
    "from numpy.random import random  \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dpath = \"C:/Users/Lzg/Desktop/data/w4/train.csv\"\n",
    "test_dpath = \"C:/Users/Lzg/Desktop/data/w4/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**三种协同过滤代码补充**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommonderSystem:\n",
    "  def __init__(self):\n",
    "    # 读入数据做初始化\n",
    "    \n",
    "    #用户和活动新的索引\n",
    "    self.userIndex = pickle.load(open(\"PE_userIndex.pkl\", 'rb'))\n",
    "    self.eventIndex = pickle.load(open(\"PE_eventIndex.pkl\", 'rb'))\n",
    "    self.n_users = len(self.userIndex)\n",
    "    self.n_items = len(self.eventIndex)\n",
    "    \n",
    "    #用户-活动关系矩阵R\n",
    "    #在train_SVD会重新从文件中读取,二者要求的格式不同，来不及统一了:(\n",
    "    self.userEventScores = sio.mmread(\"PE_userEventScores\").todense()\n",
    "    \n",
    "    #用户平均打分\n",
    "    self.nonzero_scores_index = np.transpose(np.nonzero(self.userEventScores))\n",
    "    self.n_nonzero_scores = self.nonzero_scores_index.shape[0]\n",
    "    self.mu = np.sum(self.userEventScores)/self.n_nonzero_scores\n",
    "    print(\"n_nonzero_scores = \"+str(self.n_nonzero_scores))\n",
    "    print(\"self.mu = \"+str(self.mu))\n",
    "    \n",
    "    #倒排表\n",
    "    ##每个用户参加的事件\n",
    "    self.itemsForUser = pickle.load(open(\"PE_eventsForUser.pkl\", 'rb'))\n",
    "    ##事件参加的用户\n",
    "    self.usersForItem = pickle.load(open(\"PE_usersForEvent.pkl\", 'rb'))\n",
    "    \n",
    "    #基于模型的协同过滤参数初始化,训练\n",
    "    self.init_SVD()\n",
    "    self.train_SVD(trainfile =train_dpath)\n",
    "    \n",
    "    #根据用户属性计算出的用户之间的相似度\n",
    "    self.userSimMatrix = sio.mmread(\"US_userSimMatrix\").todense()\n",
    "    \n",
    "    #根据活动属性计算出的活动之间的相似度\n",
    "    self.eventPropSim = sio.mmread(\"EV_eventPropSim\").todense()\n",
    "    self.eventContSim = sio.mmread(\"EV_eventContSim\").todense()\n",
    "    \n",
    "    #每个用户的朋友的数目\n",
    "    self.numFriends = sio.mmread(\"UF_numFriends\")\n",
    "    #用户的每个朋友参加活动的分数对该用户的影响\n",
    "    self.userFriends = sio.mmread(\"UF_userFriends\").todense()\n",
    "    \n",
    "    #活动本身的热度\n",
    "    self.eventPopularity = sio.mmread(\"EA_eventPopularity\").todense()\n",
    "\n",
    "  def init_SVD(self, K=20):\n",
    "    #初始化模型参数（for 基于模型的协同过滤SVD_CF）\n",
    "    self.K = K  \n",
    "    \n",
    "    #init parameters\n",
    "    #bias\n",
    "    self.bi = np.zeros(self.n_items)  \n",
    "    self.bu = np.zeros(self.n_users)  \n",
    "    \n",
    "    #the small matrix\n",
    "    self.P = random((self.n_users,self.K))/10*(np.sqrt(self.K))\n",
    "    self.Q = random((self.K, self.n_items))/10*(np.sqrt(self.K))  \n",
    "                  \n",
    "          \n",
    "  def train_SVD(self,trainfile = train_dpath, steps=100,gamma=0.04,Lambda=0.15):\n",
    "    #训练SVD模型（for 基于模型的协同过滤SVD_CF）\n",
    "    #gamma：为学习率\n",
    "    #Lambda：正则参数\n",
    "    \n",
    "    #偷懒了，为了和原来的代码的输入接口一样，直接从训练文件中去读取数据\n",
    "    print(\"SVD Train...\")\n",
    "    ftrain = open(trainfile, 'r')\n",
    "    ftrain.readline()\n",
    "    self.mu = 0.0\n",
    "    n_records = 0\n",
    "    uids = []  #每条记录的用户索引\n",
    "    i_ids = [] #每条记录的item索引\n",
    "    #用户-Item关系矩阵R（内容同userEventScores相同），临时变量，训练完了R不再需要\n",
    "    R = np.zeros((self.n_users, self.n_items))\n",
    "    \n",
    "    for line in ftrain:\n",
    "        cols = line.strip().split(\",\")\n",
    "        u = self.userIndex[cols[0]]  #用户\n",
    "        i = self.eventIndex[cols[1]] #活动\n",
    "        \n",
    "        uids.append(u)\n",
    "        i_ids.append(i)\n",
    "        \n",
    "        R[u,i] = int(cols[4])  #interested\n",
    "        self.mu += R[u,i]\n",
    "        n_records += 1\n",
    "    \n",
    "    ftrain.close()\n",
    "    self.mu /= n_records\n",
    "    \n",
    "    # 请补充完整SVD模型训练过程\n",
    "    for step in range(steps):\n",
    "        rmse_sum = 0.0\n",
    "        kk = np.random.permutation(self.n_nonzero_scores)\n",
    "        for j in range(self.n_nonzero_scores):\n",
    "            b = kk[j]\n",
    "            temp = self.nonzero_scores_index[b]\n",
    "            u = temp[0]\n",
    "            i = temp[1]\n",
    "            \n",
    "            #预测残差计算\n",
    "            eui = self.userEventScores[u,i]-self.pred_SVD(u,i)\n",
    "            #残差平方和\n",
    "            rmse_sum += eui**2\n",
    "            #开始进行梯度下降的更新,p,Q,bu,bi\n",
    "            for k in range(self.K):\n",
    "                self.P[u,k] += gamma*eui*self.Q[k,i]-Lambda*self.P[u,k]\n",
    "                self.Q[k,i] += gamma*eui*self.P[u,k]-Lambda*self.Q[k,i]\n",
    "                \n",
    "                self.bu[u] += gamma*(eui-Lambda*self.bu[u])\n",
    "                self.bi[i] += gamma*(eui-Lambda*self.bi[i])\n",
    "        gamma =gamma*0.93  #学习率递减  \n",
    "            \n",
    "    print (\"SVD trained\")\n",
    "    \n",
    "  def pred_SVD(self, uid, i_id):\n",
    "    #根据当前参数，预测用户uid对Item（i_id）的打分        \n",
    "    ans=self.mu + self.bi[i_id] + self.bu[uid] + np.dot(self.P[uid,:],self.Q[:,i_id])  \n",
    "        \n",
    "    #将打分范围控制在0-1之间\n",
    "    if ans>1:  \n",
    "        return 1  \n",
    "    elif ans<0:  \n",
    "        return 0\n",
    "    return ans  \n",
    "\n",
    "  def sim_cal_UserCF(self, uid1, uid2 ):\n",
    "    #请补充基于用户的协同过滤中的两个用户uid1和uid2之间的相似度（根据两个用户对item打分的相似度）\n",
    "    similarity = 0.0\n",
    "    \n",
    "    #找到两个用户都打过分的事件\n",
    "    item_common = {}   \n",
    "    for item in self.itemsForUser[uid1]:\n",
    "        if item in self.itemsForUser[uid2]:\n",
    "            item_common[item] = 1\n",
    "    n = len(item_common)\n",
    "    if(n==0):\n",
    "        similarity = 0\n",
    "        return similarity\n",
    "    #计算相似度合\n",
    "    s1 = np.array([self.userEventScores[uid1,item] for item in item_common])\n",
    "    s2 = np.array([self.userEventScores[uid2,item] for item in item_common]) \n",
    "  \n",
    "    sum1 = np.sum(s1)\n",
    "    sum2 = np.sum(s2)\n",
    "    sum1sq = np.sum(s1**2)\n",
    "    sum2sq = np.sum(s2**2)\n",
    "    psum = np.sum(s1*s2)\n",
    "    #分子\n",
    "    num = psum-(sum1*sum2/n)\n",
    "    #分母\n",
    "    den = np.sqrt((sum1sq-sum1**2/n)*(sum2sq-sum2**2/n))\n",
    "    if den == 0:\n",
    "        similarity = 0\n",
    "        return 0\n",
    "    similarity = num/den\n",
    "    return similarity  \n",
    "\n",
    "  def userCFReco(self, userId, eventId):\n",
    "    \"\"\"\n",
    "    根据User-based协同过滤，得到event的推荐度\n",
    "    基本的伪代码思路如下：\n",
    "    for item i\n",
    "      for every other user v that has a preference for i\n",
    "        compute similarity s between u and v\n",
    "        incorporate v's preference for i weighted by s into running aversge\n",
    "    return top items ranked by weighted average\n",
    "    \"\"\"\n",
    "    #请补充完整代码\n",
    "    ans = 0.0\n",
    "    u = self.userIndex[userId]\n",
    "    i = self.eventIndex[eventId]\n",
    "    sim_acc = 0.0\n",
    "    rat_acc = 0.0\n",
    "    for user in self.usersForItem[i]:\n",
    "        sim = self.sim_cal_UserCF(uid1 = user, uid2 = u )  #算一下当前用户与其他用户的相似度，在参加过同个item的用户中计算\n",
    "        if sim == 0:\n",
    "            continue\n",
    "        rat_acc += sim*userEventScores[user,i]  #打分加上用户相似度的权重\n",
    "        sim_acc += sim \n",
    "    if sim_acc == 0:   #没有用户关联\n",
    "        return self.mu\n",
    "    ans = rat_acc/sim_acc \n",
    "    if ans > 2:      \n",
    "        return 2\n",
    "    elif ans < -1:\n",
    "        return -1\n",
    "    return ans\n",
    "\n",
    "\n",
    "  def sim_cal_ItemCF(self, i_id1, i_id2):\n",
    "    #计算Item i_id1和i_id2之间的相似性\n",
    "    #请补充完整代码\n",
    "    similarity = 0.0\n",
    "    si = {}\n",
    "    for user in self.usersForItem[i_id1]:   #找到参加相同时间的用户\n",
    "        if user in self.usersForItem[i_id2]:\n",
    "            si[user] = 1\n",
    "    n = len(si)\n",
    "    if (n == 0):\n",
    "        return 0\n",
    "    s1 = np.array([self.userEventScores[u,i_id1] for u in si])\n",
    "    s2 = np.array([self.userEventScores[u,i_id2] for u in si])\n",
    "  \n",
    "    sum1 = np.sum(s1)\n",
    "    sum2 = np.sum(s2)\n",
    "    sum1sq = np.sum(s1**2)\n",
    "    sum2sq = np.sum(s2**2)\n",
    "    psum = np.sum(s1*s2)\n",
    "    #分子\n",
    "    num = psum-(sum1*sum2/n)\n",
    "    #分母\n",
    "    den = np.sqrt((sum1sq-sum1**2/n)*(sum2sq-sum2**2/n))\n",
    "    if den == 0:\n",
    "        return 0\n",
    "    simularity =  num/den   \n",
    "    return simularity      \n",
    "            \n",
    "  def eventCFReco(self, userId, eventId):    \n",
    "    \"\"\"\n",
    "    根据基于物品的协同过滤，得到Event的推荐度\n",
    "    基本的伪代码思路如下：\n",
    "    for item i \n",
    "        for every item j tht u has a preference for\n",
    "            compute similarity s between i and j\n",
    "            add u's preference for j weighted by s to a running average\n",
    "    return top items, ranked by weighted average\n",
    "    \"\"\"\n",
    "    #请补充完整代码\n",
    "    ans = 0.0\n",
    "    u = self.userIndex[userId]\n",
    "    i = self.eventIndex[eventId]\n",
    "    sim_acc = 0.0\n",
    "    rat_acc = 0.0\n",
    "    for item in self.itemsForUser[u]:\n",
    "        sim = self.sim_cal_ItemCF(item,i)\n",
    "        rat_acc += sim*self.userEventScores[u,item]   #根据相关item相似度对感兴趣程度进行加权\n",
    "        sim_acc += sim\n",
    "    if sim_acc == 0:     \n",
    "        return self.mu\n",
    "    ans = rat_acc/sim_acc\n",
    "    if ans > 2:    #取值归一到-1到2之间\n",
    "        return 2\n",
    "    elif ans <-1:\n",
    "        return -1\n",
    "    return ans\n",
    "    \n",
    "  def svdCFReco(self, userId, eventId):\n",
    "    #基于模型的协同过滤, SVD++/LFM\n",
    "    u = self.userIndex[userId]\n",
    "    i = self.eventIndex[eventId]\n",
    "\n",
    "    return self.pred_SVD(u,i)\n",
    "\n",
    "  def userReco(self, userId, eventId):\n",
    "    \"\"\"\n",
    "    类似基于User-based协同过滤，只是用户之间的相似度由用户本身的属性得到，计算event的推荐度\n",
    "    基本的伪代码思路如下：\n",
    "    for item i\n",
    "      for every other user v that has a preference for i\n",
    "        compute similarity s between u and v\n",
    "        incorporate v's preference for i weighted by s into running aversge\n",
    "    return top items ranked by weighted average\n",
    "    \"\"\"\n",
    "    i = self.userIndex[userId]\n",
    "    j = self.eventIndex[eventId]\n",
    "\n",
    "    vs = self.userEventScores[:, j]\n",
    "    sims = self.userSimMatrix[i, :]\n",
    "\n",
    "    prod = sims * vs\n",
    "\n",
    "    try:\n",
    "      return prod[0, 0] - self.userEventScores[i, j]\n",
    "    except IndexError:\n",
    "      return 0\n",
    "\n",
    "  def eventReco(self, userId, eventId):\n",
    "    \"\"\"\n",
    "    类似基于Item-based协同过滤，只是item之间的相似度由item本身的属性得到，计算Event的推荐度\n",
    "    基本的伪代码思路如下：\n",
    "    for item i \n",
    "      for every item j that u has a preference for\n",
    "        compute similarity s between i and j\n",
    "        add u's preference for j weighted by s to a running average\n",
    "    return top items, ranked by weighted average\n",
    "    \"\"\"\n",
    "    i = self.userIndex[userId]\n",
    "    j = self.eventIndex[eventId]\n",
    "    js = self.userEventScores[i, :]\n",
    "    psim = self.eventPropSim[:, j]\n",
    "    csim = self.eventContSim[:, j]\n",
    "    pprod = js * psim\n",
    "    cprod = js * csim\n",
    "    \n",
    "    pscore = 0\n",
    "    cscore = 0\n",
    "    try:\n",
    "      pscore = pprod[0, 0] - self.userEventScores[i, j]\n",
    "    except IndexError:\n",
    "      pass\n",
    "    try:\n",
    "      cscore = cprod[0, 0] - self.userEventScores[i, j]\n",
    "    except IndexError:\n",
    "      pass\n",
    "    return pscore, cscore\n",
    "\n",
    "  def userPop(self, userId):\n",
    "    \"\"\"\n",
    "    基于用户的朋友个数来推断用户的社交程度\n",
    "    主要的考量是如果用户的朋友非常多，可能会更倾向于参加各种社交活动\n",
    "    \"\"\"\n",
    "    if userId in self.userIndex:\n",
    "      i = self.userIndex[userId]\n",
    "      try:\n",
    "        return self.numFriends[0, i]\n",
    "      except IndexError:\n",
    "        return 0\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "  def friendInfluence(self, userId):\n",
    "    \"\"\"\n",
    "    朋友对用户的影响\n",
    "    主要考虑用户所有的朋友中，有多少是非常喜欢参加各种社交活动/event的\n",
    "    用户的朋友圈如果都积极参与各种event，可能会对当前用户有一定的影响\n",
    "    \"\"\"\n",
    "    nusers = np.shape(self.userFriends)[1]\n",
    "    i = self.userIndex[userId]\n",
    "    return (self.userFriends[i, :].sum(axis=0) / nusers)[0,0]\n",
    "\n",
    "  def eventPop(self, eventId):\n",
    "    \"\"\"\n",
    "    本活动本身的热度\n",
    "    主要是通过参与的人数来界定的\n",
    "    \"\"\"\n",
    "    i = self.eventIndex[eventId]\n",
    "    return self.eventPopularity[i, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**产生新的训练数据和测试数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRSData(RS, train=True, header=True):\n",
    "    \"\"\"\n",
    "    把前面user-based协同过滤 和 item-based协同过滤，以及各种热度和影响度作为特征组合在一起\n",
    "    生成新的训练数据，用于分类器分类使用\n",
    "    \"\"\"\n",
    "    \n",
    "    fn = train_dpath if train else test_dpath\n",
    "    fin = open(fn, 'r')\n",
    "    fname = \"train.csv\" if train else \"test.csv\"\n",
    "    fout = open(\"RS_\"+fname, 'w')\n",
    "    \n",
    "    #忽略第一行（列名字）\n",
    "    fin.readline().strip().split(\",\")\n",
    "    \n",
    "    # write output header\n",
    "    if header:\n",
    "      ocolnames = [\"invited\", \"userCF_reco\", \"evtCF_reco\",\"svdCF_reco\",\"user_reco\", \"evt_p_reco\",\n",
    "        \"evt_c_reco\", \"user_pop\", \"frnd_infl\", \"evt_pop\"]\n",
    "      if train:\n",
    "        ocolnames.append(\"interested\")\n",
    "        ocolnames.append(\"not_interested\")\n",
    "      fout.write(\",\".join(ocolnames) + \"\\n\")\n",
    "    \n",
    "    ln = 0\n",
    "    for line in fin:\n",
    "      ln += 1\n",
    "      if ln%500 == 0:\n",
    "          print (\"%s:%d (userId, eventId)=(%s, %s)\" % (fn, ln, userId, eventId))\n",
    "          #break;\n",
    "      \n",
    "      cols = line.strip().split(\",\")\n",
    "      userId = cols[0]\n",
    "      eventId = cols[1]\n",
    "      invited = cols[2]\n",
    "      \n",
    "      userCF_reco = RS.userCFReco(userId, eventId)\n",
    "      itemCF_reco = RS.eventCFReco(userId, eventId)\n",
    "      svdCF_reco = RS.svdCFReco(userId, eventId)\n",
    "        \n",
    "      user_reco = RS.userReco(userId, eventId)\n",
    "      evt_p_reco, evt_c_reco = RS.eventReco(userId, eventId)\n",
    "      user_pop = RS.userPop(userId)\n",
    "     \n",
    "      frnd_infl = RS.friendInfluence(userId)\n",
    "      evt_pop = RS.eventPop(eventId)\n",
    "      ocols = [invited, userCF_reco, itemCF_reco, svdCF_reco,user_reco, evt_p_reco,\n",
    "        evt_c_reco, user_pop, frnd_infl, evt_pop]\n",
    "      \n",
    "      if train:\n",
    "        ocols.append(cols[4]) # interested\n",
    "        ocols.append(cols[5]) # not_interested\n",
    "      fout.write(\",\".join(map(lambda x: str(x), ocols)) + \"\\n\")\n",
    "    \n",
    "    \n",
    "    fin.close()\n",
    "    fout.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**生成实例调用**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_nonzero_scores = 4131\n",
      "self.mu = 1.0\n",
      "SVD Train...\n",
      "SVD trained\n",
      "生成训练数据...\n",
      "\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:500 (userId, eventId)=(123290209, 1887085024)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:1000 (userId, eventId)=(272886293, 199858305)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:1500 (userId, eventId)=(395305791, 1582270949)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:2000 (userId, eventId)=(527523423, 3272728211)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:2500 (userId, eventId)=(651258472, 792632006)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:3000 (userId, eventId)=(811791433, 524756826)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:3500 (userId, eventId)=(985547042, 1269035551)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:4000 (userId, eventId)=(1107615001, 173949238)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:4500 (userId, eventId)=(1236336671, 3849306291)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:5000 (userId, eventId)=(1414301782, 2652356640)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:5500 (userId, eventId)=(1595465532, 955398943)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:6000 (userId, eventId)=(1747091728, 2131379889)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:6500 (userId, eventId)=(1914182220, 955398943)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:7000 (userId, eventId)=(2071842684, 1076364848)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:7500 (userId, eventId)=(2217853337, 3051438735)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:8000 (userId, eventId)=(2338481531, 2525447278)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:8500 (userId, eventId)=(2489551967, 520657921)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:9000 (userId, eventId)=(2650493630, 87962584)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:9500 (userId, eventId)=(2791418962, 4223848259)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:10000 (userId, eventId)=(2903662804, 2791462807)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:10500 (userId, eventId)=(3036141956, 3929507420)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:11000 (userId, eventId)=(3176074542, 3459485614)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:11500 (userId, eventId)=(3285425249, 2271782630)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:12000 (userId, eventId)=(3410667855, 1063772489)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:12500 (userId, eventId)=(3531604778, 2584839423)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:13000 (userId, eventId)=(3686871863, 53495098)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:13500 (userId, eventId)=(3833637800, 2415873572)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:14000 (userId, eventId)=(3944021305, 2096772901)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:14500 (userId, eventId)=(4075466480, 3567240505)\n",
      "C:/Users/Lzg/Desktop/data/w4/train.csv:15000 (userId, eventId)=(4197193550, 1628057176)\n",
      "生成预测数据...\n",
      "\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:500 (userId, eventId)=(182290053, 2529072432)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:1000 (userId, eventId)=(433510318, 4244463632)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:1500 (userId, eventId)=(632808865, 2845303452)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:2000 (userId, eventId)=(813611885, 2036538169)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:2500 (userId, eventId)=(1010701404, 303459881)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:3000 (userId, eventId)=(1210932037, 2529072432)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:3500 (userId, eventId)=(1452921099, 2705317682)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:4000 (userId, eventId)=(1623287180, 1626678328)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:4500 (userId, eventId)=(1855201342, 2603032829)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:5000 (userId, eventId)=(2083900381, 2529072432)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:5500 (userId, eventId)=(2318415276, 2509151803)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:6000 (userId, eventId)=(2528161539, 4025975316)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:6500 (userId, eventId)=(2749110768, 4244406355)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:7000 (userId, eventId)=(2927772127, 1532377761)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:7500 (userId, eventId)=(3199685636, 1776393554)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:8000 (userId, eventId)=(3393388475, 680270887)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:8500 (userId, eventId)=(3601169721, 154434302)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:9000 (userId, eventId)=(3828963415, 3067222491)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:9500 (userId, eventId)=(4018723397, 2522610844)\n",
      "C:/Users/Lzg/Desktop/data/w4/test.csv:10000 (userId, eventId)=(4180064266, 2658555390)\n"
     ]
    }
   ],
   "source": [
    "RS = RecommonderSystem()\n",
    "print (\"生成训练数据...\\n\")\n",
    "generateRSData(RS,train=True,  header=True)\n",
    "\n",
    "print (\"生成预测数据...\\n\")\n",
    "generateRSData(RS, train=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**看一下写好的新数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invited</th>\n",
       "      <th>userCF_reco</th>\n",
       "      <th>evtCF_reco</th>\n",
       "      <th>svdCF_reco</th>\n",
       "      <th>user_reco</th>\n",
       "      <th>evt_p_reco</th>\n",
       "      <th>evt_c_reco</th>\n",
       "      <th>user_pop</th>\n",
       "      <th>frnd_infl</th>\n",
       "      <th>evt_pop</th>\n",
       "      <th>interested</th>\n",
       "      <th>not_interested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>0.609110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.259265e-01</td>\n",
       "      <td>8.259265e-01</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>0.609110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.649779e-01</td>\n",
       "      <td>1.649779e-01</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.591891</td>\n",
       "      <td>0.948998</td>\n",
       "      <td>122.134697</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>0.609110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.024117e+00</td>\n",
       "      <td>1.024117e+00</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.102564</td>\n",
       "      <td>0.168161</td>\n",
       "      <td>0.949058</td>\n",
       "      <td>27.177369</td>\n",
       "      <td>2.443664e-07</td>\n",
       "      <td>2.443664e-07</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   invited  userCF_reco  evtCF_reco  svdCF_reco   user_reco    evt_p_reco  \\\n",
       "0        0     0.000000    0.268282    0.609110    0.000000  8.259265e-01   \n",
       "1        0     0.000000    0.268282    0.609110    0.000000  1.649779e-01   \n",
       "2        0     1.200000    0.591891    0.948998  122.134697 -1.000000e+00   \n",
       "3        0     0.000000    0.268282    0.609110    0.000000  1.024117e+00   \n",
       "4        0    -0.102564    0.168161    0.949058   27.177369  2.443664e-07   \n",
       "\n",
       "     evt_c_reco  user_pop  frnd_infl   evt_pop  interested  not_interested  \n",
       "0  8.259265e-01  0.000231        0.0 -0.000039           0               0  \n",
       "1  1.649779e-01  0.000231        0.0  0.000018           0               0  \n",
       "2 -1.000000e+00  0.000231        0.0  0.000173           1               0  \n",
       "3  1.024117e+00  0.000231        0.0  0.000016           0               0  \n",
       "4  2.443664e-07  0.000231        0.0  0.000064           0               0  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"RS_train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15398, 12)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invited</th>\n",
       "      <th>userCF_reco</th>\n",
       "      <th>evtCF_reco</th>\n",
       "      <th>svdCF_reco</th>\n",
       "      <th>user_reco</th>\n",
       "      <th>evt_p_reco</th>\n",
       "      <th>evt_c_reco</th>\n",
       "      <th>user_pop</th>\n",
       "      <th>frnd_infl</th>\n",
       "      <th>evt_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   invited  userCF_reco  evtCF_reco  svdCF_reco  user_reco  evt_p_reco  \\\n",
       "0        0     0.268282    0.268282         1.0        0.0         0.0   \n",
       "1        0     0.268282    0.268282         1.0        0.0         0.0   \n",
       "2        0     0.268282    0.268282         1.0        0.0         0.0   \n",
       "3        0     0.268282    0.268282         1.0        0.0         0.0   \n",
       "4        0     0.268282    0.268282         1.0        0.0         0.0   \n",
       "\n",
       "   evt_c_reco  user_pop  frnd_infl   evt_pop  \n",
       "0         0.0  0.000118        0.0  0.000138  \n",
       "1         0.0  0.000118        0.0  0.000030  \n",
       "2         0.0  0.000118        0.0  0.000058  \n",
       "3         0.0  0.000118        0.0  0.000069  \n",
       "4         0.0  0.000118        0.0  0.000046  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"RS_test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10237, 10)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**本次数据量很大，对用户、事件的处理虽然有大部分代码，理解还是用了很长时间，在随机梯度下降算法中开始没有用R矩阵中的用户事件索引，直接遍历train文件中的用户和事件，效率非常低，还是要尽量使用稀疏矩阵，用有效数据。特征工程方面比较难，需要积累经验。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
